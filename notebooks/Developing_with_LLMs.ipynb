{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3df43403-7733-4fb4-bc54-8a74b851a93a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### <span style=\"color:lightgray\">October 2024</span>\n",
    "\n",
    "# Programming with LLMs\n",
    "---\n",
    "\n",
    "### Matt Hall, Equinor &nbsp; `mtha@equinor.com`\n",
    "\n",
    "<span style=\"color:lightgray\">&copy;2024  Matt Hall, Equinor &nbsp; | &nbsp; licensed CC BY, please share this work</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921f2c5-3db2-4a65-a4ca-3fdceae214fa",
   "metadata": {},
   "source": [
    "## Set up an environment\n",
    "\n",
    "You will need:\n",
    "\n",
    "- `jupyter` (if you want to run this notebook)\n",
    "- `tiktoken`\n",
    "- `python-dotenv` (NOT just 'dotenv')\n",
    "- `openai`\n",
    "\n",
    "You can also optionally install LangChain (needed for the Agent demo, below):\n",
    "\n",
    "- `langchain`\n",
    "- `langchain-community`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffe09dc-a95a-4b09-ade2-d1ef2dae8bc5",
   "metadata": {},
   "source": [
    "## Set up secrets\n",
    "\n",
    "Make a file called `.env` or `secrets.txt` and give it the following contents (sort of, I will give you the correct key in the class):\n",
    "\n",
    "```text\n",
    "AZURE_OPENAI_ENDPOINT=9b0ce5dc32341ab0bf8cd9b5bf18e1f0\n",
    "AZURE_OPENAI_KEY=https://openai-common.openai.azure.com/\n",
    "```\n",
    "\n",
    "We can read environment variables from this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521eb77-af13-4916-b5b7-b2723c02a1c7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ðŸ’¥ Either use a file called `.env` to store these, or\n",
    "# ðŸ’¥ before proceeding, add secrets.txt to .gitignore\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "__ = load_dotenv(\"secrets.txt\") # If key is in a file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80f5241-d9d4-48f1-89f8-de607e81dc20",
   "metadata": {},
   "source": [
    "Now you can read the constants from the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444804d3-5cb4-456c-9ed5-4114347af943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getenv(\"AZURE_OPENAI_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cc8e82-a058-4a87-bd13-5046a578995e",
   "metadata": {},
   "source": [
    "## Define the client and make a request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcad0baa-9911-4aef-b495-a80be1365bf0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "MODEL = \"gpt-35-turbo\" # \"gpt-4o\" is multimodal but more expensive.\n",
    "\n",
    "CLIENT = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "    api_version=\"2024-02-01\",\n",
    ")\n",
    "\n",
    "prompt = \"Define AI in one sentence.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e061bfe-28db-4beb-acf9-051f1ec713ed",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid green; border-radius: 10px; padding: 8px; background: #DDFFDD\">\n",
    "<h3>EXERCISE</h3>\n",
    "\n",
    "[Check out the docs](https://platform.openai.com/docs/overview) to figure out what a `message` looks like and define it below.\n",
    "\n",
    "<a title=\"Look at the 'Developer quick start' > Python\"><strong>Hover for a hint</strong></title>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d064c17-3670-4481-9296-d8776389dd2b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "message =  # Put your message object here.\n",
    " \n",
    "CLIENT.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[message],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa62cc-ca9c-433a-9e43-9bf117ce7a2c",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid green; border-radius: 10px; padding: 8px; background: #DDFFDD\">\n",
    "<h3>EXERCISE</h3>\n",
    "\n",
    "Extract the plain text answer to your question.\n",
    "\n",
    "<a title=\"You are looking for the attribute called choices > message > content\"><strong>Hover for a hint</strong></title>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d757b59-4c2a-48e9-b129-d4ee5977f613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3b60b20-a53a-46a6-a010-10ece6b30c59",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid green; border-radius: 10px; padding: 8px; background: #DDFFDD\">\n",
    "<h3>EXERCISE</h3>\n",
    "\n",
    "Write a function called `ask()` to contain this code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3392587d-05da-4a75-b731-b6f6e68f3dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask() -> str:\n",
    "    \"\"\"Your code here.\"\"\"\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51663399-ec21-4875-a2d0-c0ca67402525",
   "metadata": {},
   "source": [
    "## A tokenizer\n",
    "\n",
    "We can use `tiktoken` for tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ee2cf4-bde2-42cd-bd10-47cce3661ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def tokenize(prompt):\n",
    "    encoding = tiktoken.encoding_for_model(MODEL)\n",
    "    tokens = encoding.encode(prompt)\n",
    "    decode = lambda token: encoding.decode_single_token_bytes(token).decode()\n",
    "    return [decode(token) for token in tokens]\n",
    "\n",
    "tokenize(\"Stratigraphically.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20221af1-6804-4ea5-a110-85edb48159c1",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "Embedding models are learned during training of the LLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9998dd3a-03e4-4e83-9077-784fe061b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-large\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    response = CLIENT.embeddings.create(input=[text], model=model)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "get_embedding(\"Equinor is an energy company.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f269db6-48f3-4f08-bf53-f5f859b4658c",
   "metadata": {},
   "source": [
    "## Conversations\n",
    "\n",
    "We can fake a conversation by storing the chat 'steps' and passing them back to the model on each new request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c528b6b-b416-4c63-b4c5-f01d451c98e7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Convo:\n",
    "    def __init__(self, temperature=0, model='gpt-35-turbo'):\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.messages = []\n",
    "\n",
    "    def ask(self, prompt):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        response = CLIENT.chat.completions.create(\n",
    "            model=self.model,\n",
    "            temperature=self.temperature,\n",
    "            max_tokens=1024,\n",
    "            messages=self.messages\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        self.messages.append({'role': 'assistant',  'content': content})\n",
    "        return content\n",
    "\n",
    "    def history(self):\n",
    "        return self.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5effb18-7f31-4108-b9d0-316857517955",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo = Convo()\n",
    "convo.ask(\"I'm Matt, who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f5d49b-8ec3-4ed5-958a-acd855c2a1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo.ask(\"What's my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc5c9cf-eef7-46e3-84eb-b378f72eb823",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo.history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620443fb-c6a1-4cb8-8686-b355d647f1dc",
   "metadata": {},
   "source": [
    "## Including images in the context\n",
    "\n",
    "Can can encode an image and send it with the prompt. Be careful about image size!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e478bde-6dbf-478d-a03a-8fdba498a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import base64\n",
    "\n",
    "def ask_about_image(prompt, image_url=None, model='gpt-4o'):\n",
    "    \"\"\"Ask ChatGPT about an (optional) image.\"\"\"\n",
    "    content = []\n",
    "    image_format = image_url.split('.')[-1]\n",
    "\n",
    "    if image_url is not None:\n",
    "        image_media_type = f\"image/{image_format}\"\n",
    "        image = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
    "        image_content = {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"}\n",
    "            }\n",
    "        content.append(image_content)\n",
    "\n",
    "    content.append({\"type\": \"text\", \"text\": prompt})\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": content},]\n",
    "    response = CLIENT.chat.completions.create(\n",
    "        model=model,  # Deployment name.\n",
    "        temperature=0.5,\n",
    "        max_tokens=1024,\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a41223-caf3-410c-a27f-6cbc2141d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/2c/Falla_normal_Morro_Solar_Peru.jpg/640px-Falla_normal_Morro_Solar_Peru.jpg\"\n",
    "Image(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e27d3-2c4a-4460-b2a1-ebb5a3e729db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_about_image(\"What kind of fault is this?\", image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca9b4ba-7dd2-44e5-b1d0-a0b4fbefc9d7",
   "metadata": {},
   "source": [
    "<span style=\"color:lightgray\">&copy; 2024 Matt Hall, Equinor &nbsp; | &nbsp; licensed CC BY, please share this work</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
