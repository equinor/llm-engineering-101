{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3df43403-7733-4fb4-bc54-8a74b851a93a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### <span style=\"color:lightgray\">EDC, November 2024</span>\n",
    "\n",
    "# Intro to programming with LLMs\n",
    "---\n",
    "\n",
    "### Matt Hall, Equinor &nbsp; `mtha@equinor.com`\n",
    "\n",
    "<span style=\"color:lightgray\">&copy;2024  Matt Hall, Equinor &nbsp; | &nbsp; licensed CC BY, please share this work</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921f2c5-3db2-4a65-a4ca-3fdceae214fa",
   "metadata": {},
   "source": [
    "## Set up an environment\n",
    "\n",
    "You will need:\n",
    "\n",
    "- `jupyter` (if you want to run this notebook)\n",
    "- `ipykernel` (if you are using Jupyter)\n",
    "- `tiktoken`\n",
    "- `python-dotenv` (NB, not just 'dotenv')\n",
    "- `openai`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffe09dc-a95a-4b09-ade2-d1ef2dae8bc5",
   "metadata": {},
   "source": [
    "## Set up secrets\n",
    "\n",
    "Make a file called `.env` or `secrets.txt` and give it the following contents (sort of, I will give you the correct key in the class):\n",
    "\n",
    "```text\n",
    "AZURE_OPENAI_ENDPOINT=<get it from Slack>\n",
    "AZURE_OPENAI_KEY=<get it from Slack>\n",
    "```\n",
    "\n",
    "We can read environment variables from this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521eb77-af13-4916-b5b7-b2723c02a1c7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ðŸ’¥ Either use a file called `.env` to store these, or\n",
    "# ðŸ’¥ before proceeding, add secrets.txt to .gitignore\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "__ = load_dotenv(\"secrets.txt\") # If key is in a file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80f5241-d9d4-48f1-89f8-de607e81dc20",
   "metadata": {},
   "source": [
    "Now you can read the constants from the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444804d3-5cb4-456c-9ed5-4114347af943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getenv(\"AZURE_OPENAI_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f614226-253f-4765-94f8-30aa4c2c82d7",
   "metadata": {},
   "source": [
    "We can make this into a `requests` call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cc8e82-a058-4a87-bd13-5046a578995e",
   "metadata": {},
   "source": [
    "## Define the client and make a request\n",
    "\n",
    "It's usually easier to use the Python API though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcad0baa-9911-4aef-b495-a80be1365bf0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "MODEL = \"gpt-35-turbo\" # \"gpt-4o\" is multimodal but more expensive.\n",
    "\n",
    "CLIENT = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "    api_version=\"2024-02-01\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0612068-0a9a-4745-8e10-e190c0375357",
   "metadata": {},
   "source": [
    "Here's the prompt we're going to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6847034a-28d1-40e3-baa9-467f1ab18a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Define AI in one sentence.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e061bfe-28db-4beb-acf9-051f1ec713ed",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid green; border-radius: 10px; padding: 8px; background: #DDFFDD\">\n",
    "<h3>EXERCISE</h3>\n",
    "\n",
    "[Check out the docs](https://platform.openai.com/docs/overview) to figure out what a `message` object looks like and define it below. Remember to use our `prompt` string when you define it.\n",
    "\n",
    "<a title=\"Look at the 'Developer quick start' > Python\"><strong>Hover for a hint</strong></title>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d064c17-3670-4481-9296-d8776389dd2b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "message =  # YOUR CODE HERE\n",
    "\n",
    "response = CLIENT.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[message],\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa62cc-ca9c-433a-9e43-9bf117ce7a2c",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid green; border-radius: 10px; padding: 8px; background: #DDFFDD\">\n",
    "<h3>EXERCISE</h3>\n",
    "\n",
    "Extract the plain text answer to your question.\n",
    "\n",
    "<a title=\"You are looking for the attribute called choices > message > content\"><strong>Hover for a hint</strong></title>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d757b59-4c2a-48e9-b129-d4ee5977f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b60b20-a53a-46a6-a010-10ece6b30c59",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid green; border-radius: 10px; padding: 8px; background: #DDFFDD\">\n",
    "<h3>EXERCISE</h3>\n",
    "\n",
    "Write a function called `ask()` to contain this code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3392587d-05da-4a75-b731-b6f6e68f3dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask():\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "ask(\"Try it out!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51663399-ec21-4875-a2d0-c0ca67402525",
   "metadata": {},
   "source": [
    "## A tokenizer\n",
    "\n",
    "We can use `tiktoken` for tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ee2cf4-bde2-42cd-bd10-47cce3661ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def tokenize(prompt):\n",
    "    encoding = tiktoken.encoding_for_model(MODEL)\n",
    "    tokens = encoding.encode(prompt)\n",
    "    decode = lambda token: encoding.decode_single_token_bytes(token).decode()\n",
    "    return [decode(token) for token in tokens]\n",
    "\n",
    "tokenize(\"Stratigraphically.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20221af1-6804-4ea5-a110-85edb48159c1",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "Embedding models are learned during training of the LLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9998dd3a-03e4-4e83-9077-784fe061b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-large\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    response = CLIENT.embeddings.create(input=[text], model=model)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "e = get_embedding(\"Equinor is an energy company.\")\n",
    "len(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de80b2e0-c32b-4696-bf44-ffee1388a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "e[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f269db6-48f3-4f08-bf53-f5f859b4658c",
   "metadata": {},
   "source": [
    "## Conversations\n",
    "\n",
    "We can fake a conversation by storing the chat 'steps' and passing them back to the model on each new request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c528b6b-b416-4c63-b4c5-f01d451c98e7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Convo:\n",
    "    def __init__(self, temperature=0, model='gpt-35-turbo'):\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.messages = []\n",
    "\n",
    "    def ask(self, prompt):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        response = CLIENT.chat.completions.create(\n",
    "            model=self.model,\n",
    "            temperature=self.temperature,\n",
    "            max_tokens=1024,\n",
    "            messages=self.messages\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        self.messages.append({'role': 'assistant',  'content': content})\n",
    "        return content\n",
    "\n",
    "    def history(self):\n",
    "        return self.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5effb18-7f31-4108-b9d0-316857517955",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo = Convo()\n",
    "convo.ask(\"I'm Matt, who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f5d49b-8ec3-4ed5-958a-acd855c2a1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo.ask(\"What's my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc5c9cf-eef7-46e3-84eb-b378f72eb823",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo.history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ece3c81-5624-491b-9700-748409852392",
   "metadata": {},
   "source": [
    "## Use the REST API\n",
    "\n",
    "We can use the web API directly, for example with Python's `requests` library. **NOTE** You might need to \n",
    "\n",
    "Here is the `curl` example from [the docs](https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cjavascript-keyless%2Ctypescript-keyless%2Cpython-new&pivots=rest-api#rest-api):\n",
    "\n",
    "```sh\n",
    "curl $AZURE_OPENAI_ENDPOINT/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-02-01 \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -H \"api-key: $AZURE_OPENAI_API_KEY\" \\\n",
    "  -d '{\"messages\":[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},{\"role\": \"user\", \"content\": \"Define AI in one sentence.\"}]}'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8480c63-a5d7-4d9d-b6ec-2193aa022298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "prompt = \"Define AI in one sentence.\"\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "}\n",
    "\n",
    "model = \"gpt-35-turbo\"\n",
    "base_url = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "url = f\"{base_url}/openai/deployments/{model}/chat/completions\"\n",
    "\n",
    "params = {\"api-version\": \"2024-02-01\"}\n",
    "\n",
    "json = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {'role': 'user', 'content': \"I'm Matt, who are you?\"},\n",
    "        {'role': 'assistant', 'content': 'Hello Matt, I am an AI digital assistant. How can I assist you today?'},\n",
    "        {'role': 'user', 'content': \"What's my name?\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "r = requests.post(url, params=params, headers=headers, json=json)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de931a4-d54c-4e16-8ebc-2406e43ceace",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620443fb-c6a1-4cb8-8686-b355d647f1dc",
   "metadata": {},
   "source": [
    "## Adding tools to the chat\n",
    "\n",
    "See [Using tools](./Using_tools.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d321ae-3e0a-4e54-ba87-13836261fcdd",
   "metadata": {},
   "source": [
    "## Including images in the context\n",
    "\n",
    "See [Sending images](./Sending_images.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca9b4ba-7dd2-44e5-b1d0-a0b4fbefc9d7",
   "metadata": {},
   "source": [
    "<span style=\"color:lightgray\">&copy; 2024 Matt Hall, Equinor &nbsp; | &nbsp; licensed CC BY, please share this work</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
